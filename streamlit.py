# app.py â€” ì „ê³µ ì„ íƒ â†’ ìê²©ì¦ ì¹´ë“œ(ë‚œì´ë„/í•©ê²©ë¥ /êµ¬ì¡°/ê²€ì •íšŸìˆ˜) ìŠ¤íŠ¸ë¦¼ë¦¿ ëŒ€ì‹œë³´ë“œ
# ìš”êµ¬ íŒ¨í‚¤ì§€: streamlit, pandas, numpy, altair, plotly
# í„°ë¯¸ë„: streamlit run app.py

import re
from pathlib import Path
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px

# ==============================
# í˜ì´ì§€ ì„¤ì •
# ==============================
st.set_page_config(page_title="ì „ê³µë³„ ìê²©ì¦ íƒìƒ‰ ëŒ€ì‹œë³´ë“œ", layout="wide", page_icon="ğŸ“")
st.title("ğŸ“ ì „ê³µë³„ ìê²©ì¦ ë‚œì´ë„Â·í•©ê²©ë¥  ëŒ€ì‹œë³´ë“œ")
st.caption("ì¢Œì¸¡ì—ì„œ ì „ê³µ/ê²€ìƒ‰/í•„í„°ë¥¼ ê³ ë¥´ê³ , ì˜¤ë¥¸ìª½ ì¹´ë“œë¡œ ìê²©ì¦ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# ==============================
# íŒŒì¼ ê²½ë¡œ(í•„ìš”ì‹œ ìˆ˜ì •)
# ==============================
CERT_PATH_CANDIDATES = [
    "/mnt/data/1010ìê²©ì¦ë°ì´í„°_í†µí•©.xlsx",
    "1010ìê²©ì¦ë°ì´í„°_í†µí•©.xlsx",
    "./data/1010ìê²©ì¦ë°ì´í„°_í†µí•©.xlsx",
]
MAJOR_PATH_CANDIDATES = [
    "/mnt/data/1013ì „ê³µì •ë³´í†µí•©_final.xlsx",
    "1013ì „ê³µì •ë³´í†µí•©_final.xlsx",
    "./data/1013ì „ê³µì •ë³´í†µí•©_final.xlsx",
]

# ==============================
# ì»¬ëŸ¼ íŒíŠ¸(ì´ë¦„ì´ ë‹¤ë¥´ë©´ ì—¬ê¸°ì„œ ê³ ì • ë§¤í•‘ ê°€ëŠ¥)
# ==============================
COLUMN_HINTS = {
    "id": ["ìê²©ì¦ID", "license_id", "ID", "ìê²©ì¦_id"],
    "name": ["ìê²©ì¦ëª…", "license_name", "ì´ë¦„", "ì¢…ëª©ëª…", "ìê²©ëª…"],
    "cls": ["ë¶„ë¥˜", "ìê²©ì¦_ë¶„ë¥˜", "classification"],
    "grade_code": ["ë“±ê¸‰ì½”ë“œ", "ìê²©ì¦_ë“±ê¸‰_ì½”ë“œ", "grade_code", "ë“±ê¸‰"],
    "freq": ["ê²€ì •íšŸìˆ˜", "ì—°ê°„ê²€ì •íšŸìˆ˜", "ì‹œí—˜íšŸìˆ˜", "ì—°ê°„ì‹œí—˜íšŸìˆ˜"],
    "structure": ["ì‹œí—˜êµ¬ì¡°", "ì‹œí—˜_êµ¬ì¡°", "structure"],
    "has_written": ["í•„ê¸°", "í•„ê¸°ì—¬ë¶€", "í•„ê¸°_ì—¬ë¶€"],
    "has_practical": ["ì‹¤ê¸°", "ì‹¤ê¸°ì—¬ë¶€", "ì‹¤ê¸°_ì—¬ë¶€"],
    "has_interview": ["ë©´ì ‘", "ë©´ì ‘ì—¬ë¶€", "ë©´ì ‘_ì—¬ë¶€"],
    # ì—°ë„ë³„ í•©ê²©ë¥ Â·ì‘ì‹œì ìˆ˜ëŠ” íŒ¨í„´ ê²€ìƒ‰(ì•„ë˜)ë¡œ ì²˜ë¦¬
}

YEARS = [2022, 2023, 2024]

# ë‚œì´ë„ ê°€ì¤‘ì¹˜(ìŠ¬ë¼ì´ë“œ ê¸°ì¤€ê°’, í•„ìš”ì‹œ ì¡°ì •)
SCORING_WEIGHTS = {
    "w_invpass": 1.0,          # ì—­í•©ê²©ë¥  ê°€ì¤‘(ê¸°ë³¸ì¶•)
    "w_trust_floor": 0.5,       # ì‹ ë¢°ê°€ì¤‘ í•˜í•œ
    "w_trust_span": 0.5,        # ì‹ ë¢°ê°€ì¤‘ ìƒí•œ(í•˜í•œ+span*w)
    "add_practical": 0.15,      # ì‹¤ê¸° ê°€ì‚°
    "add_interview": 0.10,      # ë©´ì ‘ ê°€ì‚°
    "add_extra_component": 0.05,# (í•„ìˆ˜ ì™¸ êµ¬ì„±ìš”ì†Œ ìˆì„ ë•Œ) ì„ íƒì  ê°€ì‚°
    "add_cls_prof": 0.20,       # êµ­ê°€ì „ë¬¸
    "add_cls_tech": 0.10,       # êµ­ê°€ê¸°ìˆ 
    "add_cls_private": 0.00,    # êµ­ê°€ë¯¼ê°„
    "add_grade_code_max": 0.20, # (500-ë“±ê¸‰)/400 * 0.20
    "add_freq_max": 0.10,       # (íšŸìˆ˜ ì ì„ìˆ˜ë¡ +) ì •ê·œí™” ìƒí•œ
}

CLASS_MAP = {
    "êµ­ê°€ì „ë¬¸": SCORING_WEIGHTS["add_cls_prof"],
    "êµ­ê°€ê¸°ìˆ ": SCORING_WEIGHTS["add_cls_tech"],
    "êµ­ê°€ë¯¼ê°„": SCORING_WEIGHTS["add_cls_private"],
}

# ==============================
# ìœ í‹¸
# ==============================
def pick_first_col(cols, df_cols):
    for c in cols:
        if c in df_cols:
            return c
    return None

def find_col_by_hint(df, key):
    col = pick_first_col(COLUMN_HINTS.get(key, []), df.columns)
    return col

def find_year_cols(df, year, kind):
    """
    kind: 'í•©ê²©ë¥ ' or 'ì‘ì‹œì' or 'í•„ê¸°í•©ê²©ë¥ '/'ì‹¤ê¸°í•©ê²©ë¥ '
    ê·œì¹™: 'YYYY' in col and kind token in col
    """
    y = str(year)
    mask = df.columns.str.contains(y)
    cols = df.columns[mask]
    if "í•©ê²©ë¥ " in kind:
        cols = [c for c in cols if "í•©ê²©" in c and "ë¥ " in c]
    elif kind == "ì‘ì‹œì":
        cols = [c for c in cols if ("ì‘ì‹œ" in c and "ìˆ˜" in c) or ("ì‘ì‹œì" in c)]
    return cols

def coalesce_numeric(s):
    """ë¬¸ì/ê²°ì¸¡ ì„ì—¬ë„ ìˆ«ìë§Œ ìµœëŒ€í•œ ë½‘ì•„ëƒ„"""
    return pd.to_numeric(s, errors="coerce")

def parse_structure_flags(row, col_struct, col_w, col_p, col_i):
    """ì‹œí—˜êµ¬ì¡° ë¬¸ìì—´ ë˜ëŠ” ê°œë³„ ì»¬ëŸ¼ì—ì„œ í•„ê¸°/ì‹¤ê¸°/ë©´ì ‘ flag ì¶”ì¶œ"""
    has_w = False
    has_p = False
    has_i = False
    if col_struct and pd.notna(row.get(col_struct, np.nan)):
        txt = str(row[col_struct])
        has_w |= bool(re.search("í•„ê¸°", txt))
        has_p |= bool(re.search("ì‹¤ê¸°", txt))
        has_i |= bool(re.search("ë©´ì ‘", txt))
    if col_w:
        has_w |= (coalesce_numeric(row.get(col_w, 0)) > 0)
    if col_p:
        has_p |= (coalesce_numeric(row.get(col_p, 0)) > 0)
    if col_i:
        has_i |= (coalesce_numeric(row.get(col_i, 0)) > 0)
    return has_w, has_p, has_i

def weighted_inverse_passrate(overall_rate, total_applicants, all_applicants):
    """
    overall_rate: 0~100 ê°€ì •. ì—†ìœ¼ë©´ NaN.
    total_applicants: í‘œë³¸ ì‘ì‹œììˆ˜ í•©
    all_applicants: ì „ì²´ ë°ì´í„° ì‘ì‹œììˆ˜ ì‹œë¦¬ì¦ˆ(ì •ê·œí™”ìš©)
    """
    if pd.isna(overall_rate):
        return np.nan
    inv = (100.0 - overall_rate) / 100.0
    # ì‹ ë¢°ê°€ì¤‘: log1p(ì‘ì‹œì) ì •ê·œí™”
    if total_applicants is not None and total_applicants > 0 and all_applicants.notna().any():
        norm = np.log1p(total_applicants) / np.nanmax(np.log1p(all_applicants))
        w = SCORING_WEIGHTS["w_trust_floor"] + SCORING_WEIGHTS["w_trust_span"] * float(norm)
    else:
        w = 1.0  # ì‘ì‹œì ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¤‘ë¦½
    return inv * SCORING_WEIGHTS["w_invpass"] * w

def grade_code_bonus(code):
    # (500 - code)/400 * 0.20, codeê°€ ì‘ì„ìˆ˜ë¡ ë‚œì´ë„â†‘
    c = coalesce_numeric(code)
    if pd.isna(c):
        return 0.0
    return max(0.0, min(1.0, (500.0 - float(c)) / 400.0)) * SCORING_WEIGHTS["add_grade_code_max"]

def freq_bonus(freq_value, all_freq):
    # íšŸìˆ˜ ì ì„ìˆ˜ë¡ +, 0~1ë¡œ ì—­ì •ê·œí™”í•˜ì—¬ add_freq_max ìŠ¤ì¼€ì¼
    f = coalesce_numeric(freq_value)
    if pd.isna(f) or f < 0:
        return 0.0
    if all_freq.notna().sum() == 0:
        return 0.0
    # ë‚®ì„ìˆ˜ë¡ ê°€ì‚° â†’ (max - f) / (max - min)
    fmin = float(np.nanmin(all_freq))
    fmax = float(np.nanmax(all_freq))
    if fmax == fmin:
        return 0.0
    score01 = (fmax - float(f)) / (fmax - fmin)
    return score01 * SCORING_WEIGHTS["add_freq_max"]

def class_bonus(cls_label):
    if pd.isna(cls_label):
        return 0.0
    return CLASS_MAP.get(str(cls_label).strip(), 0.0)

def structure_bonus(has_w, has_p, has_i, extra_components=0):
    s = 0.0
    if has_p: s += SCORING_WEIGHTS["add_practical"]
    if has_i: s += SCORING_WEIGHTS["add_interview"]
    if extra_components and extra_components > 0:
        s += SCORING_WEIGHTS["add_extra_component"] * float(extra_components)
    return s

def qcut_1to5(series):
    # ê°’ì´ ì ìœ¼ë©´ qcut ì‹¤íŒ¨ â†’ ë“±ê°„ë¶„í•  ëŒ€ì²´
    s = series.copy()
    s = s.replace([np.inf, -np.inf], np.nan)
    valid = s.dropna()
    if valid.nunique() >= 5:
        try:
            bins = pd.qcut(valid, 5, labels=[1,2,3,4,5])
            out = pd.Series(index=s.index, dtype="float")
            out.loc[valid.index] = bins.astype(float)
            return out
        except Exception:
            pass
    # fallback: ë“±ê°„ë¶„í• 
    mn, mx = float(np.nanmin(valid)) if valid.size else 0.0, float(np.nanmax(valid)) if valid.size else 1.0
    def to_band(x):
        if pd.isna(x): return np.nan
        if mx == mn: return 3.0
        r = (x - mn) / (mx - mn + 1e-12)
        return float(np.clip(np.floor(r*5)+1, 1, 5))
    return s.apply(to_band)

@st.cache_data(show_spinner=False)
def read_excel_first(paths):
    for p in paths:
        if Path(p).exists():
            try:
                return pd.read_excel(p)
            except Exception:
                pass
    return None

# ==============================
# ë°ì´í„° ë¡œë“œ
# ==============================
df_cert = read_excel_first(CERT_PATH_CANDIDATES)
df_major = read_excel_first(MAJOR_PATH_CANDIDATES)

with st.sidebar:
    st.subheader("ë°ì´í„° ì†ŒìŠ¤")
    c1, c2 = st.columns(2)
    c1.write("ìê²©ì¦ íŒŒì¼:")
    c1.code(next((p for p in CERT_PATH_CANDIDATES if Path(p).exists()), CERT_PATH_CANDIDATES[0]), language="bash")
    c2.write("ì „ê³µ íŒŒì¼:")
    c2.code(next((p for p in MAJOR_PATH_CANDIDATES if Path(p).exists()), MAJOR_PATH_CANDIDATES[0]), language="bash")

if df_cert is None:
    st.error("ìê²©ì¦ ì—‘ì…€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒë‹¨ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì—…ë¡œë”ë¡œ ì˜¬ë ¤ì£¼ì„¸ìš”.")
    up = st.file_uploader("ìê²©ì¦ ì—‘ì…€ ì—…ë¡œë“œ(.xlsx)", type=["xlsx"])
    if up:
        df_cert = pd.read_excel(up)
if df_major is None:
    st.warning("ì „ê³µ ì—‘ì…€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ê³µ í•„í„° ì—†ì´ ì „ì²´ ìê²©ì¦ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    up2 = st.file_uploader("ì „ê³µ ì—‘ì…€ ì—…ë¡œë“œ(.xlsx)", type=["xlsx"])
    if up2:
        df_major = pd.read_excel(up2)

if df_cert is None:
    st.stop()

# ==============================
# í•µì‹¬ ì»¬ëŸ¼ íƒìƒ‰/ë§¤í•‘
# ==============================
cid_col = find_col_by_hint(df_cert, "id")
name_col = find_col_by_hint(df_cert, "name")
cls_col = find_col_by_hint(df_cert, "cls")
grade_col = find_col_by_hint(df_cert, "grade_code")
freq_col = find_col_by_hint(df_cert, "freq")
struct_col = find_col_by_hint(df_cert, "structure")
w_col = find_col_by_hint(df_cert, "has_written")
p_col = find_col_by_hint(df_cert, "has_practical")
i_col = find_col_by_hint(df_cert, "has_interview")

# í•„ìˆ˜: ìê²©ì¦ëª…/IDëŠ” ë˜ë„ë¡ ìˆì–´ì•¼ ì¹´ë“œê°€ ê¹”ë”
if name_col is None:
    # ì´ë¦„ì´ ì—†ìœ¼ë©´ ì–´ë–¤ ì²« ì»¬ëŸ¼ìœ¼ë¡œë¼ë„ ëŒ€ì²´
    name_col = df_cert.columns[0]
if cid_col is None:
    # IDê°€ ì—†ìœ¼ë©´ ì´ë¦„ìœ¼ë¡œ ëŒ€ì²´ ID
    cid_col = name_col

df = df_cert.copy()

# ==============================
# ì—°ë„ë³„ í•©ê²©ë¥ /ì‘ì‹œì íƒìƒ‰ â†’ OVERALL í•©ê²©ë¥ Â·ì´ ì‘ì‹œì ê³„ì‚°
# ==============================
overall_by_year = {}
applicants_by_year = {}
for y in YEARS:
    # ìš°ì„ ìˆœìœ„: (OVERALL í•©ê²©ë¥ ) â†’ (í•„ê¸°/ì‹¤ê¸° í‰ê· )
    cand_rate_overall = [c for c in find_year_cols(df, y, "í•©ê²©ë¥ ") if re.search("OVERALL|ì¢…í•©|ì „ì²´", c, re.IGNORECASE)]
    if cand_rate_overall:
        overall_by_year[y] = coalesce_numeric(df[cand_rate_overall[0]])
    else:
        # í•„ê¸°/ì‹¤ê¸° í‰ê·  ì‹œë„
        cand_written = [c for c in find_year_cols(df, y, "í•©ê²©ë¥ ") if "í•„ê¸°" in c]
        cand_prac    = [c for c in find_year_cols(df, y, "í•©ê²©ë¥ ") if "ì‹¤ê¸°" in c]
        wr = coalesce_numeric(df[cand_written[0]]) if cand_written else np.nan
        pr = coalesce_numeric(df[cand_prac[0]]) if cand_prac else np.nan
        overall_by_year[y] = pd.Series(np.nanmean(np.vstack([wr, pr]), axis=0))

    cand_apps = find_year_cols(df, y, "ì‘ì‹œì")
    if cand_apps:
        # ì—°ë„ ë‚´ ì‘ì‹œì í•©
        apps = df[cand_apps].apply(coalesce_numeric).sum(axis=1, skipna=True)
    else:
        apps = pd.Series([np.nan]*len(df))
    applicants_by_year[y] = apps

# 3ê°œ ì—°ë„ í‰ê· (ìˆëŠ” ê°’ë§Œ)
overall_cols = []
for y, s in overall_by_year.items():
    coln = f"{y}_OVERALL"
    df[coln] = s
    overall_cols.append(coln)

df["OVERALL_PASS(%)"] = df[overall_cols].apply(lambda r: np.nanmean([v for v in r if pd.notna(v)]), axis=1)

# ì´ ì‘ì‹œì í•©
app_cols = []
for y, s in applicants_by_year.items():
    coln = f"{y}_APPLICANTS"
    df[coln] = s
    app_cols.append(coln)
df["APPLICANTS_TOTAL"] = df[app_cols].sum(axis=1, skipna=True)

# ==============================
# êµ¬ì¡° í”Œë˜ê·¸/í…ìŠ¤íŠ¸
# ==============================
flags = df.apply(lambda row: parse_structure_flags(row, struct_col, w_col, p_col, i_col), axis=1, result_type="expand")
df[["HAS_WRIT","HAS_PRAC","HAS_INTV"]] = flags

def build_struct_label(row):
    parts = []
    if row["HAS_WRIT"]: parts.append("í•„ê¸°")
    if row["HAS_PRAC"]: parts.append("ì‹¤ê¸°")
    if row["HAS_INTV"]: parts.append("ë©´ì ‘")
    return "+".join(parts) if parts else ("(ë¯¸ìƒ)" if pd.isna(row.get(struct_col, np.nan)) else str(row.get(struct_col)))

df["STRUCT_TXT"] = df.apply(build_struct_label, axis=1)

# ==============================
# ë‚œì´ë„ ì ìˆ˜ ê³„ì‚°
# ==============================
# (1) ì—­í•©ê²©ë¥ Ã—ì‹ ë¢°ê°€ì¤‘
df["_invpass_trust"] = df.apply(
    lambda r: weighted_inverse_passrate(r["OVERALL_PASS(%)"], r["APPLICANTS_TOTAL"], df["APPLICANTS_TOTAL"]),
    axis=1
)

# (2) êµ¬ì¡°/ë“±ê¸‰/ë¶„ë¥˜/ê²€ì •íšŸìˆ˜ ê°€ì‚°
if freq_col is None:
    # ê²€ì •íšŸìˆ˜ ì—†ìœ¼ë©´ 0 ë³´ë„ˆìŠ¤
    freq_series = pd.Series([np.nan]*len(df))
else:
    freq_series = coalesce_numeric(df[freq_col])

df["_bonus_freq"] = freq_series.apply(lambda v: freq_bonus(v, coalesce_numeric(freq_series)))
df["_bonus_grade"] = df[grade_col].apply(grade_code_bonus) if grade_col else 0.0
df["_bonus_class"] = df[cls_col].apply(class_bonus) if cls_col else 0.0

# êµ¬ì¡° ë³´ë„ˆìŠ¤
df["_bonus_struct"] = df.apply(
    lambda r: structure_bonus(r["HAS_WRIT"], r["HAS_PRAC"], r["HAS_INTV"], extra_components=0),
    axis=1
)

# ìµœì¢… í‘œë³¸ ì ìˆ˜
df["DIFF_SCORE"] = df[["_invpass_trust","_bonus_freq","_bonus_grade","_bonus_class","_bonus_struct"]].sum(axis=1, skipna=True)

# 5ë¶„ìœ„ ë“±ê¸‰í™”(1=ì‰¬ì›€~5=ì–´ë ¤ì›€)
df["DIFF_LEVEL(1-5)"] = qcut_1to5(df["DIFF_SCORE"])

# ==============================
# ì „ê³µ ë§¤í•‘(ì„ íƒ)
# ==============================
major_name_cols = []
if df_major is not None:
    # ì „ê³µëª… í›„ë³´
    for c in ["ì „ê³µëª…","ì „ê³µ","í•™ê³¼","ì „ê³µ(í†µí•©)","major","dept"]:
        if c in df_major.columns: major_name_cols.append(c)
    major_id_col = pick_first_col(["ìê²©ì¦ID","license_id","ìê²©ì¦_id","ID"], df_major.columns)
else:
    major_id_col = None

with st.sidebar:
    st.header("ê²€ìƒ‰/í•„í„°")
    # ì „ê³µ ì„ íƒ
    if df_major is not None and major_name_cols and major_id_col:
        major_col = major_name_cols[0]
        major_list = ["(ì „ì²´)"] + sorted(pd.Series(df_major[major_col].astype(str).unique()).dropna().tolist())
        sel_major = st.selectbox("ì „ê³µ ì„ íƒ", major_list, index=0)
        if sel_major != "(ì „ì²´)":
            major_ids = df_major.loc[df_major[major_col].astype(str)==sel_major, major_id_col].astype(str).unique().tolist()
        else:
            major_ids = None
    else:
        sel_major = "(ì „ê³µ íŒŒì¼ ë¯¸ì§€ì •)"
        major_ids = None

    # í‚¤ì›Œë“œ
    q = st.text_input("ìê²©ì¦ëª… í‚¤ì›Œë“œ", value="")

    # ë¶„ë¥˜
    cls_opts = sorted(df[cls_col].dropna().astype(str).unique().tolist()) if cls_col else []
    sel_cls = st.multiselect("ë¶„ë¥˜(êµ­ê°€ì „ë¬¸/êµ­ê°€ê¸°ìˆ /êµ­ê°€ë¯¼ê°„)", options=cls_opts, default=cls_opts[:])

    # ë“±ê¸‰ì½”ë“œ ë²”ìœ„
    if grade_col and coalesce_numeric(df[grade_col]).notna().any():
        gmin = int(np.nanmin(coalesce_numeric(df[grade_col])))
        gmax = int(np.nanmax(coalesce_numeric(df[grade_col])))
        gmin = min(gmin,100); gmax = max(gmax,500)
        sel_g = st.slider("ë“±ê¸‰ì½”ë“œ ë²”ìœ„(ë‚®ì„ìˆ˜ë¡ ê³ ë‚œë„)", min_value=100, max_value=500, value=(max(100,gmin), min(500,gmax)), step=50)
    else:
        sel_g = (100, 500)

    # êµ¬ì¡° í•„í„°(ì„ íƒ ì‹œ í•´ë‹¹ ìš”ì†Œ í¬í•¨)
    fcol1, fcol2, fcol3 = st.columns(3)
    want_w = fcol1.toggle("í•„ê¸°", value=False)
    want_p = fcol2.toggle("ì‹¤ê¸°", value=False)
    want_i = fcol3.toggle("ë©´ì ‘", value=False)

    # ë‚œì´ë„ ë“±ê¸‰ í•„í„°
    sel_lv = st.multiselect("ë‚œì´ë„ ë“±ê¸‰(1=ì‰¬ì›€~5=ì–´ë ¤ì›€)", options=[1,2,3,4,5], default=[1,2,3,4,5])

    # í‘œì‹œ ê°œìˆ˜
    topk = st.slider("í‘œì‹œ ê°œìˆ˜", min_value=6, max_value=60, value=18, step=6)

# ==============================
# í•„í„° ì ìš©
# ==============================
f = df.copy()

# ì „ê³µ í•„í„°
if major_ids:
    f = f[f[cid_col].astype(str).isin([str(x) for x in major_ids])]

# í‚¤ì›Œë“œ
if q:
    f = f[f[name_col].astype(str).str.contains(q, case=False, na=False)]

# ë¶„ë¥˜
if cls_col and sel_cls:
    f = f[f[cls_col].astype(str).isin(sel_cls)]

# ë“±ê¸‰ì½”ë“œ
if grade_col:
    gv = coalesce_numeric(f[grade_col])
    f = f[(gv>=sel_g[0]) & (gv<=sel_g[1])]

# êµ¬ì¡°
if want_w: f = f[f["HAS_WRIT"]==True]
if want_p: f = f[f["HAS_PRAC"]==True]
if want_i: f = f[f["HAS_INTV"]==True]

# ë‚œì´ë„ ë“±ê¸‰
f = f[f["DIFF_LEVEL(1-5)"].isin(sel_lv)]

# ì •ë ¬: ì–´ë ¤ìš´ ìˆœ(ì ìˆ˜ desc) â†’ í•©ê²©ë¥  asc
f = f.sort_values(["DIFF_SCORE","OVERALL_PASS(%)"], ascending=[False, True])

st.markdown(f"#### ê²°ê³¼: {len(f):,}ê±´")
st.caption("ì •ë ¬: ë‚œì´ë„ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ â†’ í•©ê²©ë¥  ì˜¤ë¦„ì°¨ìˆœ")

# ==============================
# ì¹´ë“œ ë Œë”ëŸ¬
# ==============================
def mini_passrate_chart(row):
    data = []
    for y in YEARS:
        v = row.get(f"{y}_OVERALL", np.nan)
        if not pd.isna(v):
            data.append({"ì—°ë„": int(y), "í•©ê²©ë¥ (%)": float(v)})
    if not data:
        return None
    cdf = pd.DataFrame(data)
    chart = (
        alt.Chart(cdf)
        .mark_line(point=True)
        .encode(
            x=alt.X("ì—°ë„:O", title=None),
            y=alt.Y("í•©ê²©ë¥ (%):Q", scale=alt.Scale(domain=[0,100])),
            tooltip=["ì—°ë„","í•©ê²©ë¥ (%)"]
        )
        .properties(height=120)
    )
    return chart

def badge(text):
    return f'<span style="padding:2px 8px;border-radius:999px;background:#f1f3f5;border:1px solid #dee2e6;font-size:11px;margin-right:6px;">{text}</span>'

def render_card(row):
    title = str(row.get(name_col, ""))
    cid = str(row.get(cid_col, ""))
    cls_ = str(row.get(cls_col, "")) if cls_col else ""
    grade_v = row.get(grade_col, "")
    freq_v = row.get(freq_col, "")
    struct_txt = str(row.get("STRUCT_TXT",""))
    pass_overall = row.get("OVERALL_PASS(%)", np.nan)
    diff_lv = row.get("DIFF_LEVEL(1-5)", np.nan)
    diff_sc = row.get("DIFF_SCORE", np.nan)

    # ìƒë‹¨
    st.markdown(f"##### {title}  <small style='color:#868e96'>[{cid}]</small>", unsafe_allow_html=True)
    st.markdown(
        badge(f"ë¶„ë¥˜: {cls_}") + 
        badge(f"ë“±ê¸‰ì½”ë“œ: {grade_v}") +
        badge(f"ê²€ì •íšŸìˆ˜: {freq_v}") +
        badge(f"êµ¬ì¡°: {struct_txt}"),
        unsafe_allow_html=True
    )

    # ì§€í‘œ 2ì—´
    c1, c2, c3 = st.columns([1,1,1])
    with c1:
        st.metric("ë‚œì´ë„ ë“±ê¸‰", f"{int(diff_lv) if not pd.isna(diff_lv) else '-'} / 5", help=f"ì ìˆ˜ {diff_sc:.3f}" if not pd.isna(diff_sc) else None)
    with c2:
        st.metric("í•©ê²©ë¥ (í‰ê· )", f"{pass_overall:.1f}%" if not pd.isna(pass_overall) else "-")
    with c3:
        apps = row.get("APPLICANTS_TOTAL", np.nan)
        st.metric("ì´ ì‘ì‹œììˆ˜(í•©)", f"{int(apps):,}" if not pd.isna(apps) else "-")

    # ë¯¸ë‹ˆ ë¼ì¸ì°¨íŠ¸
    ch = mini_passrate_chart(row)
    if ch is not None:
        st.altair_chart(ch, use_container_width=True)

    st.divider()

# ==============================
# ì¹´ë“œ ê·¸ë¦¬ë“œ ì¶œë ¥
# ==============================
# í–‰ ë‹¨ìœ„ë¡œ 3ì—´ ì¹´ë“œ
rows = list(f.head(topk).to_dict(orient="records"))
if not rows:
    st.info("ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
else:
    ncol = 3
    for i in range(0, len(rows), ncol):
        cols = st.columns(ncol)
        for j in range(ncol):
            if i+j < len(rows):
                with cols[j]:
                    render_card(rows[i+j])

# ==============================
# ë‹¤ìš´ë¡œë“œ
# ==============================
with st.expander("ë‹¤ìš´ë¡œë“œ"):
    dl_cols = [cid_col, name_col, cls_col, grade_col, freq_col, "STRUCT_TXT", "OVERALL_PASS(%)", "APPLICANTS_TOTAL", "DIFF_SCORE", "DIFF_LEVEL(1-5)"]
    dl_cols = [c for c in dl_cols if (c in f.columns)]
    st.dataframe(f[dl_cols], use_container_width=True)
    st.download_button(
        "CSV ë‹¤ìš´ë¡œë“œ",
        data=f[dl_cols].to_csv(index=False).encode("utf-8-sig"),
        file_name="license_filtered.csv",
        mime="text/csv"
    )

# ==============================
# ë„ì›€ë§
# ==============================
with st.expander("ë‚œì´ë„ ì‚°ì¶œ ë¡œì§(ìš”ì•½)"):
    st.markdown(
        """
- **ì—­í•©ê²©ë¥ (1 - í•©ê²©ë¥ /100)**ì„ ê¸°ë³¸ ì¶•ìœ¼ë¡œ, **ì‘ì‹œììˆ˜ log1p ì •ê·œí™”**ë¡œ ì‹ ë¢°ê°€ì¤‘.
- êµ¬ì¡° ê°€ì‚°: **ì‹¤ê¸° +0.15, ë©´ì ‘ +0.10** (ì¶”ê°€ êµ¬ì„±ìš”ì†Œê°€ ìˆë‹¤ë©´ +0.05/ê°œ ì˜µì…˜).
- ë¶„ë¥˜ ê°€ì‚°: **êµ­ê°€ì „ë¬¸ +0.20, êµ­ê°€ê¸°ìˆ  +0.10, êµ­ê°€ë¯¼ê°„ 0**.
- ë“±ê¸‰ì½”ë“œ: **(500-ë“±ê¸‰)/400 Ã— 0.20** (ì½”ë“œê°€ ë‚®ì„ìˆ˜ë¡ ê°€ì‚°).
- ê²€ì •íšŸìˆ˜: **íšŸìˆ˜ ì ì„ìˆ˜ë¡ +**, 0~0.10 ë²”ìœ„ë¡œ ì •ê·œí™”.
- ì¢…í•©ì ìˆ˜ë¥¼ **5ë¶„ìœ„(qcut)**ë¡œ ë‚˜ëˆ  **1(ì‰¬ì›€)~5(ì–´ë ¤ì›€)** ë“±ê¸‰í™”.
- ìƒë‹¨ `SCORING_WEIGHTS`ì—ì„œ ìˆ˜ì¹˜ë¥¼ ë°”ë¡œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
    )

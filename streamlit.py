# -*- coding: utf-8 -*-
# ì „ê³µë³„ ìê²©ì¦ ëŒ€ì‹œë³´ë“œ â€” ë‚´ë¶€ ë‚œì´ë„ ê³„ì‚° + í•˜ë‹¨ í˜ì´ì§€ë„¤ì´ì…˜
# 'êµ­ê°€ê¸°ìˆ ìê²©' ì„ íƒ ì‹œì—ë§Œ ë“±ê¸‰ì½”ë“œ í•„í„° ë…¸ì¶œ
# ë¼ì´ì„ ìŠ¤ ì¹´ë“œ â†’ [ê´€ë ¨ ì§ë¬´ ë³´ê¸°] â†’ ì§ë¬´ ì¹´ë“œ ëª©ë¡(í•™ê³¼ëª… í‘œì‹œ) â†’ [ìƒì„¸ ì •ë³´] â†’ ì§ì—…ì •ë³´ ìƒì„¸ íŒ¨ë„

import re
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# â”€â”€ Matplotlib í•œê¸€ + ê³µí†µ ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from matplotlib import font_manager, rcParams

def use_korean_font():
    candidates = ["Malgun Gothic", "AppleGothic", "NanumGothic", "Noto Sans CJK KR", "DejaVu Sans"]
    installed = {f.name for f in font_manager.fontManager.ttflist}
    for f in candidates:
        if f in installed:
            rcParams["font.family"] = f
            break
    rcParams["axes.unicode_minus"] = False

def apply_pretty_style():
    plt.rcParams.update({
        "axes.titleweight": "bold",
        "axes.titlesize": 15,
        "axes.labelsize": 11,
        "xtick.labelsize": 10,
        "ytick.labelsize": 10,
        "grid.linestyle": "--",
        "grid.alpha": 0.35,
    })

def hide_spines(ax):
    for s in ["top", "right"]:
        if s in ax.spines: ax.spines[s].set_visible(False)

use_korean_font()
apply_pretty_style()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ì „ê³µë³„ ìê²©ì¦ ëŒ€ì‹œë³´ë“œ", layout="wide", page_icon="ğŸ“")
st.title("ğŸ“ ì „ê³µë³„ ìê²©ì¦ ë‚œì´ë„Â·í•©ê²©ë¥  ëŒ€ì‹œë³´ë“œ")

CERT_PATHS  = ["1010ìê²©ì¦ë°ì´í„°_í†µí•©.xlsx", "data/data_cert.xlsx"]
MAJOR_PATHS = ["1013ì „ê³µì •ë³´í†µí•©_final.xlsx", "data/data_major.xlsx"]
JOBS_PATHS  = ["ì§ë¬´ë¶„ë¥˜ë°ì´í„°_ë³‘í•©ì™„_with_ID_v3.xlsx", "data/data_jobs.xlsx"]     # ìê²©ì¦ID â†” jobdicSeq ë§¤í•‘
JOBINFO_PATHS = ["ì§ì—…ì •ë³´_ë°ì´í„°.xlsx", "data/job_info.xlsx"]                     # jobdicSeq ìƒì„¸ ì •ë³´

YEARS  = [2022, 2023, 2024]
PHASES = ["1ì°¨", "2ì°¨", "3ì°¨"]
GRADE_LABELS = {100:"ê¸°ìˆ ì‚¬(100)", 200:"ê¸°ëŠ¥ì¥(200)", 300:"ê¸°ì‚¬(300)", 400:"ì‚°ì—…ê¸°ì‚¬(400)", 500:"ê¸°ëŠ¥ì‚¬(500)"}

# ë‚œì´ë„ ê°€ì¤‘ì¹˜
SCORING = {
    "trust_floor":0.5, "trust_span":0.5,   # ì‘ì‹œììˆ˜ ì‹ ë¢°ê°€ì¤‘
    "bonus_prac":0.15, "bonus_intv":0.10,  # êµ¬ì¡° ê°€ì‚°
    "bonus_grade_max":0.20,                # (500-ë“±ê¸‰)/400 Ã— max
    "bonus_freq_max":0.10,                 # ê²€ì •íšŸìˆ˜(ì ì„ìˆ˜ë¡ +)
    "bonus_prof":0.20, "bonus_tech":0.10, "bonus_priv":0.00  # ë¶„ë¥˜ ê°€ì‚°
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_first(paths):
    for p in paths:
        try:
            return pd.read_excel(p)
        except Exception:
            continue
    return None

df        = read_first(CERT_PATHS)
df_major  = read_first(MAJOR_PATHS)
df_jobs   = read_first(JOBS_PATHS)
df_jobinfo= read_first(JOBINFO_PATHS)

if df is None:
    st.error("ìê²©ì¦ ì—‘ì…€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

# ê³µí†µ í‚¤
NAME_COL, ID_COL, CLS_COL = "ìê²©ì¦ëª…", "ìê²©ì¦ID", "ìê²©ì¦_ë¶„ë¥˜"
GRADE_COL, GRADE_TYPE_COL = "ìê²©ì¦_ë“±ê¸‰_ì½”ë“œ", "ë“±ê¸‰_ë¶„ë¥˜"
FREQ_COL, STRUCT_COL      = "ê²€ì • íšŸìˆ˜", "ì‹œí—˜ì¢…ë¥˜"
W_COL, P_COL, I_COL       = "í•„ê¸°", "ì‹¤ê¸°", "ë©´ì ‘"

# ì§ë¬´/ì§ì—… ì •ë³´ í‚¤ ì •ê·œí™”
# â”€â”€ í‚¤ ì •ê·œí™”(ë¬¸ìì—´ + strip) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
JOB_ID_COL  = "ìê²©ì¦ID"
JOB_SEQ_COL = "jobdicSeq"

def _to_key(series):
    return pd.Series(series, dtype="object").astype(str).str.strip()

if df_jobs is not None:
    if JOB_ID_COL  in df_jobs.columns:
        df_jobs[JOB_ID_COL] = _to_key(df_jobs[JOB_ID_COL])
    if JOB_SEQ_COL in df_jobs.columns:
        df_jobs[JOB_SEQ_COL] = _to_key(df_jobs[JOB_SEQ_COL])

if df_jobinfo is not None and JOB_SEQ_COL in df_jobinfo.columns:
    df_jobinfo[JOB_SEQ_COL] = _to_key(df_jobinfo[JOB_SEQ_COL])

PASS_RATE_COLS = {
    2022: {"1ì°¨":"2022ë…„ 1ì°¨ í•©ê²©ë¥ ","2ì°¨":"2022ë…„ 2ì°¨ í•©ê²©ë¥ ","3ì°¨":"2022ë…„ 3ì°¨ í•©ê²©ë¥ "},
    2023: {"1ì°¨":"2023ë…„ 1ì°¨ í•©ê²©ë¥ ","2ì°¨":"2023ë…„ 2ì°¨ í•©ê²©ë¥ ","3ì°¨":"2023ë…„ 3ì°¨ í•©ê²©ë¥ "},
    2024: {"1ì°¨":"2024ë…„ 1ì°¨ í•©ê²©ë¥ ","2ì°¨":"2024ë…„ 2ì°¨ í•©ê²©ë¥ ","3ì°¨":"2024ë…„ 3ì°¨ í•©ê²©ë¥ "},
}
APPL_COLS = {
    2022: {"1ì°¨":"2022ë…„ 1ì°¨ ì‘ì‹œì ìˆ˜","2ì°¨":"2022ë…„ 2ì°¨ ì‘ì‹œììˆ˜","3ì°¨":"2022ë…„ 3ì°¨ ì‘ì‹œììˆ˜"},
    2023: {"1ì°¨":"2023ë…„ 1ì°¨ ì‘ì‹œì ìˆ˜","2ì°¨":"2023ë…„ 2ì°¨ ì‘ì‹œì ìˆ˜","3ì°¨":"2023ë…„ 3ì°¨ ì‘ì‹œì ìˆ˜"},
    2024: {"1ì°¨":"2024ë…„ 1ì°¨ ì‘ì‹œì ìˆ˜","2ì°¨":"2024ë…„ 2ì°¨ ì‘ì‹œì ìˆ˜","3ì°¨":"2024ë…„ 3ì°¨ ì‘ì‹œì ìˆ˜"},
}

num = lambda s: pd.to_numeric(s, errors="coerce")

def class_bonus(label:str)->float:
    s=str(label)
    if "ì „ë¬¸" in s: return SCORING["bonus_prof"]
    if "ê¸°ìˆ " in s: return SCORING["bonus_tech"]
    if "ë¯¼ê°„" in s: return SCORING["bonus_priv"]
    return 0.0

def trust_weight(avg_app, all_avg_apps)->float:
    if pd.notna(avg_app) and all_avg_apps.notna().any():
        norm = np.log1p(avg_app) / np.nanmax(np.log1p(all_avg_apps))
        return SCORING["trust_floor"] + SCORING["trust_span"] * float(norm)
    return 1.0

def grade_bonus(code)->float:
    c = num(code)
    if pd.isna(c): return 0.0
    return max(0.0, min(1.0, (500.0 - float(c)) / 400.0)) * SCORING["bonus_grade_max"]

# â€œìƒì‹œ/ìˆ˜ì‹œâ€ ë“± í…ìŠ¤íŠ¸ â†’ ê³„ì‚°ìš© ìˆ«ì(í‘œì‹œëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ)
def freq_to_num(x):
    if x is None: return np.nan
    if isinstance(x, (int, float)) and not np.isnan(x): return float(x)
    s = str(x).strip()
    if s == "" or s.lower() == "nan": return np.nan
    # í•©ë¦¬ì  ê¸°ë³¸ê°’: ìƒì‹œ=12íšŒ/ë…„, ìˆ˜ì‹œ=6íšŒ/ë…„, ì—°ì¤‘=12íšŒ
    if "ìƒì‹œ" in s: return 12.0
    if "ìˆ˜ì‹œ" in s: return 6.0
    if "ì—°ì¤‘" in s: return 12.0
    m = re.search(r"(\d+)", s)
    return float(m.group(1)) if m else np.nan

def freq_bonus(v, all_freq_series)->float:
    f = pd.to_numeric(v, errors="coerce")
    if pd.isna(f) or all_freq_series.notna().sum()==0: return 0.0
    fmin, fmax = float(np.nanmin(all_freq_series)), float(np.nanmax(all_freq_series))
    if fmax == fmin: return 0.0
    # íšŸìˆ˜ ì ì„ìˆ˜ë¡ ì–´ë ¤ì›€ ë³´ì •(+)
    return ((fmax - float(f)) / (fmax - fmin)) * SCORING["bonus_freq_max"]

def qcut_1to5(s:pd.Series)->pd.Series:
    s = s.replace([np.inf, -np.inf], np.nan)
    valid = s.dropna()
    if valid.nunique() >= 5:
        try:
            bins = pd.qcut(valid, 5, labels=[1,2,3,4,5])
            out = pd.Series(index=s.index, dtype="float")
            out.loc[valid.index] = bins.astype(float)
            return out
        except Exception:
            pass
    mn = float(np.nanmin(valid)) if len(valid) else 0.0
    mx = float(np.nanmax(valid)) if len(valid) else 1.0
    def band(x):
        if pd.isna(x): return np.nan
        if mx == mn:   return 3.0
        r=(x-mn)/(mx-mn+1e-12)
        return float(np.clip(np.floor(r*5)+1,1,5))
    return s.apply(band)

def fmt_int(x):
    if pd.isna(x): return "-"
    try: return f"{int(round(float(x))):,}"
    except Exception: return "-"

def badge(t):
    return f"<span style='padding:2px 8px;border-radius:999px;background:#f8f9fa;border:1px solid #dee2e6;font-size:11px;margin-right:6px;'>{t}</span>"

def _num_in_text(x):
    s = "" if x is None else str(x)
    m = re.search(r"[-+]?\d*\.?\d+", s)  # ë¬¸ìì—´ ì† ì²« ìˆ«ìë§Œ ì¶”ì¶œ
    return float(m.group(0)) if m else np.nan


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•©ê²©ë¥ /ì‘ì‹œì ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for ph in PHASES:
    cols = [PASS_RATE_COLS[y][ph] for y in YEARS if PASS_RATE_COLS[y][ph] in df.columns]
    df[f"PASS_{ph}_AVG(22-24)"] = df[cols].apply(num).mean(axis=1, skipna=True) if cols else np.nan

df["OVERALL_PASS(%)"] = df[[f"PASS_{ph}_AVG(22-24)" for ph in PHASES]].mean(axis=1, skipna=True)

app_cols = [APPL_COLS[y][ph] for y in YEARS for ph in PHASES if APPL_COLS[y][ph] in df.columns]
df["APPLICANTS_AVG"] = df[app_cols].apply(num).mean(axis=1, skipna=True) if app_cols else np.nan

# êµ¬ì¡° í”Œë˜ê·¸/í…ìŠ¤íŠ¸
def parse_structure(r):
    t = str(r.get(STRUCT_COL, "") or "")
    has_w = ("í•„ê¸°" in t) or (num(r.get(W_COL, 0)) > 0)
    has_p = ("ì‹¤ê¸°" in t) or (num(r.get(P_COL, 0)) > 0)
    has_i = ("ë©´ì ‘" in t) or (num(r.get(I_COL, 0)) > 0)
    txt   = "+".join([x for x,b in (("í•„ê¸°",has_w),("ì‹¤ê¸°",has_p),("ë©´ì ‘",has_i)) if b])
    return has_w, has_p, has_i, txt

df[["HAS_W","HAS_P","HAS_I","STRUCT_TXT"]] = df.apply(parse_structure, axis=1, result_type="expand")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‚œì´ë„(ë‚´ë¶€ ê³„ì‚°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²€ì •íšŸìˆ˜: í‘œì‹œìš©ì€ ì›ë¬¸, ê³„ì‚°ìš©ì€ ìˆ«ìí™”
freq_numeric = df[FREQ_COL].apply(freq_to_num) if FREQ_COL in df.columns else pd.Series([np.nan]*len(df))
inv_overall  = (100.0 - df["OVERALL_PASS(%)"]) / 100.0
trust_w      = df["APPLICANTS_AVG"].apply(lambda a: trust_weight(a, df["APPLICANTS_AVG"]))
bonus_freq   = freq_numeric.apply(lambda v: freq_bonus(v, freq_numeric))
score = (inv_overall.fillna(0)*trust_w
         + df[CLS_COL].apply(class_bonus).fillna(0.0)
         + df[GRADE_COL].apply(grade_bonus).fillna(0.0)
         + bonus_freq.fillna(0.0)
         + df.apply(lambda r: (SCORING["bonus_prac"] if r["HAS_P"] else 0.0)
                              + (SCORING["bonus_intv"] if r["HAS_I"] else 0.0), axis=1))
df["DIFF_SCORE"]      = score
df["DIFF_LEVEL(1-5)"] = qcut_1to5(df["DIFF_SCORE"])

# ë“±ê¸‰ì½”ë“œ í›„ë³´(100ë‹¨ìœ„)
grade_nums     = pd.to_numeric(df[GRADE_COL], errors="coerce")
grade_buckets  = [b for b in [100,200,300,400,500] if (grade_nums.round(-2)==b).any()]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ì „ê³µ í•„í„°")
    use_major     = st.toggle("ì „ê³µìœ¼ë¡œ í•„í„°", value=False)
    selected_ids  = None

    if use_major:
        if df_major is None:
            st.error("ì „ê³µ ì—‘ì…€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            major_name_col, major_id_col = "í•™ê³¼ëª…", "ìê²©ì¦ID"
            majors_all = sorted(df_major[major_name_col].astype(str).unique().tolist())
            qmaj       = st.text_input("ì „ê³µ ê²€ìƒ‰", value="")
            majors_view= [m for m in majors_all if qmaj.strip()=="" or qmaj.lower() in m.lower()]
            sel_major  = st.selectbox("í•™ê³¼ëª…", ["(ì„ íƒ)"]+majors_view, index=0)
            if sel_major != "(ì„ íƒ)":
                selected_ids = (
                    df_major.loc[df_major[major_name_col].astype(str)==sel_major, major_id_col]
                           .astype(str).unique().tolist()
                )
        st.divider()

    st.header("ê²€ìƒ‰ / í•„í„°")
    q = st.text_input("ìê²©ì¦ëª… ê²€ìƒ‰", value="")
    cls_options = sorted(df[CLS_COL].dropna().astype(str).unique().tolist())
    sel_cls     = st.multiselect("ìê²©ì¦ ë¶„ë¥˜", options=cls_options, default=cls_options)

    # 'êµ­ê°€ê¸°ìˆ ìê²©' í¬í•¨ ì‹œì—ë§Œ ë“±ê¸‰ì½”ë“œ í•„í„°
    show_grade_filter = any(("êµ­ê°€ê¸°ìˆ " in c) or ("ê¸°ìˆ " in c) for c in sel_cls)
    if show_grade_filter:
        sel_buckets = st.multiselect(
            "ë“±ê¸‰ì½”ë“œ(100ë‹¨ìœ„)",
            options=grade_buckets or [100,200,300,400,500],
            format_func=lambda x: GRADE_LABELS.get(x, str(x)),
            default=grade_buckets or [100,200,300,400,500]
        )
    else:
        sel_buckets = None
        st.caption("ë“±ê¸‰ì½”ë“œëŠ” â€˜êµ­ê°€ê¸°ìˆ ìê²©â€™ ì„ íƒ ì‹œ í™œì„±í™”ë©ë‹ˆë‹¤.")

    c1, c2, c3 = st.columns(3)
    want_w = c1.toggle("í•„ê¸°", value=False)
    want_p = c2.toggle("ì‹¤ê¸°", value=False)
    want_i = c3.toggle("ë©´ì ‘", value=False)

    sel_lv    = st.multiselect("ë‚œì´ë„ ë“±ê¸‰(1~5)", options=[1,2,3,4,5], default=[1,2,3,4,5])
    page_size = st.slider("í˜ì´ì§€ë‹¹ ì¹´ë“œ ìˆ˜", 6, 60, 12, step=6)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•„í„° ì ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
f = df.copy()
if selected_ids:
    f = f[f[ID_COL].astype(str).isin([str(x) for x in selected_ids])]
if q:
    f = f[f[NAME_COL].astype(str).str.contains(q, case=False, na=False)]
if sel_cls:
    f = f[f[CLS_COL].astype(str).isin(sel_cls)]
if sel_buckets:
    f = f[pd.to_numeric(f[GRADE_COL], errors="coerce").round(-2).isin(sel_buckets)]
if want_w: f = f[f["HAS_W"]==True]
if want_p: f = f[f["HAS_P"]==True]
if want_i: f = f[f["HAS_I"]==True]
f = f[f["DIFF_LEVEL(1-5)"].isin(sel_lv)]
f = f.sort_values(["DIFF_SCORE","OVERALL_PASS(%)"], ascending=[False, True])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í˜ì´ì§€ë„¤ì´ì…˜(í•˜ë‹¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
total = len(f)
max_pages = max(1, int(np.ceil(total / page_size)))
if "page" not in st.session_state: st.session_state.page = 1
if st.session_state.page > max_pages: st.session_state.page = 1
if st.session_state.page < 1: st.session_state.page = 1
page = st.session_state.page
start, end = (page-1)*page_size, (page-1)*page_size + page_size
page_df = f.iloc[start:end]

st.markdown(f"#### ê²°ê³¼: {total:,}ê±´ (í˜ì´ì§€ {page}/{max_pages})")
st.caption("ì •ë ¬: ë‚œì´ë„ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ â†’ í•©ê²©ë¥  ì˜¤ë¦„ì°¨ìˆœ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¹´ë“œ ë Œë”ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def license_card(row):
    title, rid = str(row[NAME_COL]), str(row[ID_COL])
    cls        = str(row.get(CLS_COL, ""))
    grade      = row.get(GRADE_COL, "")
    freq_disp  = row.get(FREQ_COL, "")       # í‘œì‹œëŠ” ì›ë¬¸
    struct     = row.get("STRUCT_TXT", "")
    diff_lv    = row.get("DIFF_LEVEL(1-5)", np.nan)
    diff_sc    = row.get("DIFF_SCORE", np.nan)
    apps       = row.get("APPLICANTS_AVG", np.nan)

    with st.container(border=True):
        st.markdown(f"##### {title}  <small style='color:#868e96'>[{rid}]</small>", unsafe_allow_html=True)
        st.markdown(
            badge(f"ë¶„ë¥˜: {cls}") +
            badge(f"ë“±ê¸‰ì½”ë“œ: {grade}") +
            badge(f"ê²€ì •íšŸìˆ˜: {freq_disp}") +
            badge(f"êµ¬ì¡°: {struct}"),
            unsafe_allow_html=True
        )

        c1, c2, c3 = st.columns(3)
        with c1: st.metric("ë‚œì´ë„ ë“±ê¸‰", f"{int(diff_lv) if pd.notna(diff_lv) else '-'} / 5",
                           help=(f"ì ìˆ˜ {diff_sc:.3f}" if pd.notna(diff_sc) else None))
        with c2: st.metric("í‰ê·  ì‘ì‹œììˆ˜", fmt_int(apps))
        with c3:
            ov = row.get("OVERALL_PASS(%)", np.nan)
            st.metric("ì „ì²´ í•©ê²©ë¥ (í‰ê· )", f"{ov:.1f}%" if pd.notna(ov) else "-")

        p1, p2, p3 = st.columns(3)
        with p1:
            v = row.get("PASS_1ì°¨_AVG(22-24)", np.nan)
            st.metric("1ì°¨ í•©ê²©ë¥ (3ë…„í‰ê· )", f"{v:.1f}%" if pd.notna(v) else "-")
        with p2:
            v = row.get("PASS_2ì°¨_AVG(22-24)", np.nan)
            st.metric("2ì°¨ í•©ê²©ë¥ (3ë…„í‰ê· )", f"{v:.1f}%" if pd.notna(v) else "-")
        with p3:
            v = row.get("PASS_3ì°¨_AVG(22-24)", np.nan)
            st.metric("3ì°¨ í•©ê²©ë¥ (3ë…„í‰ê· )", f"{v:.1f}%" if pd.notna(v) else "-")

        # ê´€ë ¨ ì§ë¬´ ë³´ê¸°
        if (df_jobs is not None) and (JOB_ID_COL in df_jobs.columns):
            if st.button("ê´€ë ¨ ì§ë¬´ ë³´ê¸°", key=f"jobbtn_{rid}", use_container_width=True):
                st.session_state["selected_license"] = rid
                # ì§ë¬´ ìƒì„¸ ì„ íƒì€ ì´ˆê¸°í™”
                st.session_state.pop("selected_job_seq", None)

rows = list(page_df.to_dict(orient="records"))
if not rows:
    st.info("ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
else:
    ncol = 3
    for i in range(0, len(rows), ncol):
        cols = st.columns(ncol)
        for j in range(ncol):
            if i+j < len(rows):
                with cols[j]:
                    license_card(rows[i+j])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê´€ë ¨ ì§ë¬´(ì¹´ë“œ) & ìƒì„¸ íŒ¨ë„(í˜ì´ì§€ í•˜ë‹¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sel_license = st.session_state.get("selected_license")

# â”€â”€ ì„ íƒí•œ ìê²©ì¦ì˜ 3ë…„ í‰ê·  í•©ê²©ë¥ (1Â·2Â·3ì°¨) ë¼ì¸ì°¨íŠ¸ â”€â”€
if sel_license is not None:
    lic = df[df[ID_COL].astype(str) == str(sel_license)]
    if not lic.empty:
        row = lic.iloc[0]
        x_labels = ["1ì°¨", "2ì°¨", "3ì°¨"]
        y_vals   = [
            pd.to_numeric(row.get("PASS_1ì°¨_AVG(22-24)"), errors="coerce"),
            pd.to_numeric(row.get("PASS_2ì°¨_AVG(22-24)"), errors="coerce"),
            pd.to_numeric(row.get("PASS_3ì°¨_AVG(22-24)"), errors="coerce"),
        ]
        x_plot = [l for l, v in zip(x_labels, y_vals) if pd.notna(v)]
        y_plot = [float(v) for v in y_vals if pd.notna(v)]

        if len(y_plot) > 0:
            _, mid, _ = st.columns([1, 2, 1])   # ê°€ìš´ë° ì •ë ¬ & í­ ì•ˆì •
            with mid:
                x_idx = np.arange(len(x_plot))
                fig, ax = plt.subplots(figsize=(7, 3.6))
                line, = ax.plot(x_idx, y_plot, marker="o", linewidth=2.6, markersize=6, solid_capstyle="round")
                # ë¼ì¸ ì•„ë˜ ì€ì€í•œ ì˜ì—­
                ax.fill_between(x_idx, y_plot, 0, alpha=0.10)
                ax.set_xticks(x_idx, x_plot)
                ax.set_ylim(0, 100)
                ax.set_yticks(np.arange(0, 101, 20))
                ax.set_ylabel("í•©ê²©ë¥ (%)", labelpad=6)
                ax.set_title("3ë…„ í‰ê·  í•©ê²©ë¥  (1Â·2Â·3ì°¨)", pad=6)
                ax.grid(True, which="major")
                hide_spines(ax)
                # ê°’ ë¼ë²¨
                for xi, yi in zip(x_idx, y_plot):
                    ax.annotate(f"{yi:.1f}%", (xi, yi), textcoords="offset points", xytext=(0, 8), ha="center")
                fig.tight_layout()
                st.pyplot(fig, use_container_width=True)

# 1) ê´€ë ¨ ì§ë¬´ ì¹´ë“œë“¤ (í•™ê³¼ëª… í‘œê¸°)
if df_jobs is not None and (JOB_ID_COL in df_jobs.columns) and sel_license:
    jobs = df_jobs[df_jobs[JOB_ID_COL] == str(sel_license).strip()].copy()

    st.subheader("ê´€ë ¨ ì§ë¬´")
    if jobs.empty:
        st.info("ì—°ê²°ëœ ì§ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ë™ì¼ jobdicSeq ë¬¶ì–´ì„œ í•™ê³¼ëª… í•©ì¹˜ê¸°
        if "í•™ê³¼ëª…" in jobs.columns:
            jobs = (
                jobs.assign(í•™ê³¼ëª…=jobs["í•™ê³¼ëª…"].astype(str).str.strip())
                    .groupby([JOB_SEQ_COL, "ì§ì—…ëª…"], as_index=False)["í•™ê³¼ëª…"]
                    .agg(lambda s: ", ".join(pd.Series(s).dropna().unique()))
            )

        ncol = 2
        job_rows = list(jobs.to_dict(orient="records"))
        for i in range(0, len(job_rows), ncol):
            cols = st.columns(ncol)
            for j in range(ncol):
                if i + j >= len(job_rows):
                    break
                jr = job_rows[i + j]
                seq   = str(jr.get(JOB_SEQ_COL, "")).strip()
                title = str(jr.get("ì§ì—…ëª…", "(ì§ì—…ëª… ë¯¸ìƒ)"))
                major = str(jr.get("í•™ê³¼ëª…", "")).strip()

                with cols[j]:
                    with st.container(border=True):
                        st.markdown(
                            f"**{title}**  <small style='color:#868e96'>[{seq}]</small>",
                            unsafe_allow_html=True
                        )
                        if major:
                            st.caption(f"ê´€ë ¨ í•™ê³¼: {major}")

                        # ìƒì„¸ íŒ¨ë„ì€ í˜ì´ì§€ 'ë§¨ í•˜ë‹¨'ì— ë Œë” â†’ ì—¬ê¸°ì„œëŠ” ì„ íƒë§Œ ì €ì¥
                        if st.button("ìƒì„¸ ì •ë³´", key=f"jobinfo_btn__{sel_license}__{seq}",
                                     use_container_width=True):
                            st.session_state["selected_job_seq"]   = seq
                            st.session_state["selected_job_title"] = title

# 2) ìƒì„¸ íŒ¨ë„(í˜ì´ì§€ í•˜ë‹¨ ê³ ì • ë Œë”)
sel_job = st.session_state.get("selected_job_seq")

st.divider()
st.subheader("ì§ì—… ìƒì„¸ ì •ë³´")

if (sel_job is None) or (df_jobinfo is None) or (JOB_SEQ_COL not in (df_jobinfo.columns if df_jobinfo is not None else [])):
    st.info("ìƒì„¸ ë³´ê¸°ë¥¼ ì„ íƒí•˜ë©´ ì´ê³³ì— í‘œì‹œë©ë‹ˆë‹¤.")
else:
    detail = df_jobinfo[df_jobinfo[JOB_SEQ_COL] == str(sel_job).strip()]
    if detail.empty:
        st.warning("ì§ì—…ì •ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤(í‚¤ ë¶ˆì¼ì¹˜). ì•„ë˜ 'ë””ë²„ê·¸'ì—ì„œ í‚¤ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.")
    else:
        r = detail.iloc[0].astype(str).str.strip().to_dict()
        title = st.session_state.get("selected_job_title") or r.get("ì§ì—…ëª…", "")

        with st.container(border=True):
            st.markdown(
                f"### {title}  <small style='color:#868e96'>[{str(sel_job).strip()}]</small>",
                unsafe_allow_html=True
            )

            # ì ìˆ˜ ìš”ì•½(ìˆì„ ë•Œë§Œ)
            score_keys = ["ë³´ìƒ","ê³ ìš©ì•ˆì •","ë°œì „ê°€ëŠ¥ì„±","ê·¼ë¬´ì—¬ê±´","ì§ì—…ì „ë¬¸ì„±","ê³ ìš©í‰ë“±"]
            cols = st.columns(3)
            k = 0
            for sk in score_keys:
                val = r.get(sk, "")
                if val and val.lower() not in ["nan", "none"]:
                    with cols[k % 3]:
                        st.metric(sk, val)
                    k += 1
            # â”€â”€ 6ê°œ ì§€í‘œ ë ˆì´ë”ì°¨íŠ¸ â”€â”€
            radar_keys   = ["ë³´ìƒ","ê³ ìš©ì•ˆì •","ë°œì „ê°€ëŠ¥ì„±","ê·¼ë¬´ì—¬ê±´","ì§ì—…ì „ë¬¸ì„±","ê³ ìš©í‰ë“±"]
            radar_labels = radar_keys[:]
            radar_vals   = [_num_in_text(r.get(k, "")) for k in radar_keys]

            if any(pd.notna(v) for v in radar_vals):
                vals = [0.0 if pd.isna(v) else float(v) for v in radar_vals]
                angles = np.linspace(0, 2*np.pi, len(vals), endpoint=False)

                _, mid, _ = st.columns([1, 2, 1])
                with mid:
                    fig = plt.figure(figsize=(5.2, 5.2))
                    ax = plt.subplot(111, polar=True)
                    # ìœ„ìª½(12ì‹œ)ì—ì„œ ì‹œì‘ & ì‹œê³„ë°©í–¥
                    ax.set_theta_offset(np.pi / 2)
                    ax.set_theta_direction(-1)

                    angles_c = np.concatenate([angles, angles[:1]])
                    vals_c   = np.concatenate([vals,   vals[:1]])
                    ax.plot(angles_c, vals_c, linewidth=2.4)
                    ax.fill(angles_c, vals_c, alpha=0.12)

                    ax.set_thetagrids(np.degrees(angles), radar_labels)
                    ax.set_ylim(0, 100)
                    ax.set_rgrids([20, 40, 60, 80, 100], angle=90, fontsize=9)
                    ax.set_title("ì§ì—… ì§€í‘œ ë ˆì´ë”", pad=12)
                    ax.grid(True, linestyle="--", alpha=0.35)
                    ax.spines["polar"].set_linewidth(0.9)

                    # ê¼­ì§“ì  ê°’ í‘œì‹œ
                    for ang, val in zip(angles, vals):
                        ax.annotate(f"{val:.0f}", (ang, val), textcoords="offset points", xytext=(0, 6), ha="center")

                    fig.tight_layout()
                    st.pyplot(fig, use_container_width=True)

            st.divider()

            # ê¸´ í…ìŠ¤íŠ¸ ì„¹ì…˜
            sections = [
                ("ì§ì—…ì „ë§ìš”ì•½","ì§ì—…ì „ë§ìš”ì•½"),
                ("ì·¨ì—…ë°©ë²•","ì·¨ì—…ë°©ë²•"),
                ("ì¤€ë¹„ê³¼ì •","ì¤€ë¹„ê³¼ì •"),
                ("êµìœ¡ê³¼ì •","êµìœ¡ê³¼ì •"),
                ("ì ì„±","ì ì„±"),
                ("ê³ ìš©í˜•íƒœ","ê³ ìš©í˜•íƒœ"),
                ("ê³ ìš©ë¶„ë¥˜","ê³ ìš©ë¶„ë¥˜"),
                ("í‘œì¤€ë¶„ë¥˜","í‘œì¤€ë¶„ë¥˜"),
                ("ì§ë¬´êµ¬ë¶„","ì§ë¬´êµ¬ë¶„"),
                ("ì´ˆì„","ì´ˆì„"),
                ("ìœ ì‚¬ì§ì—…ëª…","ìœ ì‚¬ì§ì—…ëª…"),
            ]
            for key, label in sections:
                val = (r.get(key) or "").strip()
                if not val or val.lower() in ["nan", "none"]:
                    continue
                st.markdown(f"**{label}**")
                st.markdown(
                    "<div style='white-space:pre-wrap; line-height:1.7; "
                    "background:#f8fbff; border:1px solid #e9ecef; border-radius:10px; "
                    "padding:12px; margin:6px 0 16px 0;'>"
                    f"{val}</div>",
                    unsafe_allow_html=True
                )

            c1, c2 = st.columns([1,1])
            with c1:
                if st.button("ìƒì„¸ ë³´ê¸° ë‹«ê¸°", key="close_jobinfo", use_container_width=True):
                    st.session_state.pop("selected_job_seq", None)
                    st.session_state.pop("selected_job_title", None)
                    if hasattr(st, "rerun"): st.rerun()
            with c2:
                if st.button("ê´€ë ¨ ì§ë¬´ ì„ íƒ í•´ì œ", key="clear_jobs", use_container_width=True):
                    st.session_state.pop("selected_license", None)
                    st.session_state.pop("selected_job_seq", None)
                    st.session_state.pop("selected_job_title", None)
                    if hasattr(st, "rerun"): st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•˜ë‹¨ í˜ì´ì§€ ì»¨íŠ¸ë¡¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
c_prev, c_info, c_next = st.columns([1, 2, 1])
def _safe_rerun():
    if hasattr(st, "rerun"):
        st.rerun()
    elif hasattr(st, "experimental_rerun"):
        st.experimental_rerun()

with c_prev:
    if st.button("â—€ ì´ì „", use_container_width=True, disabled=(page <= 1), key="prev_btn"):
        st.session_state.page = max(1, page - 1); _safe_rerun()
with c_info:
    new_page = st.number_input("í˜ì´ì§€", min_value=1, max_value=max_pages, value=page, step=1, key="page_num")
    if new_page != page:
        st.session_state.page = int(new_page); _safe_rerun()
with c_next:
    if st.button("ë‹¤ìŒ â–¶", use_container_width=True, disabled=(page >= max_pages), key="next_btn"):
        st.session_state.page = min(max_pages, page + 1); _safe_rerun()
